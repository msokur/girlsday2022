{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FXD6wJ7TKtxh"
      },
      "source": [
        "**Bildklassifikation mit einem neuronalen Netz**\n",
        "\n",
        "Tutorial von:\n",
        "https://learnopencv.com/pytorch-for-beginners-image-classification-using-pre-trained-models/\n",
        "\n",
        "\n",
        "Hi! In diesem Tutorial werden wir Neuronale Netze zur Klassifikation von Bildern kennenlernen und benutzen. Das Ziel ist es, mit Hilfe von einem schon trainierten Netz, das eine Gruppe von Wissenschaftler*innen auf einer sehr großen Menge von Bildern trainiert hat, Objekte auf Bildern zu erkennen. Wenn also beispielsweise ein Hund auf dem Bild zu erkennen ist, soll das Netz in der Lage sein, das zu erkennen und uns ein \"Hund\" als Ausgabe zu geben. \n",
        "\n",
        "Solche Modelle zur Objekterkennung auf Bildern kennt ihr zum Beispiel schon von von eurem Handy: wenn ihr beispielsweise Snapchat nutzt, erkennt die App euer Gesicht ganz automatisch. In diesem Fall ist das zu erkennende Objekt also euer Gesicht. Oder vielleicht seid ihr mal in einem Parkhaus gewesen, bei dem ihr kein Ticket mehr ziehen , sondern lediglich euer Kennzeichen zum Bezahlen angeben müsst - das bei der Einfahrt per Kamera automatisch erkannt wurde. Hier ist das zu erkennende Objekt dann das Kennzeichen. \n",
        "\n",
        "Habt ihr noch andere Ideen, wo euch Objekterkennung mal begenet ist? \n",
        "\n",
        "Klickt euch durch die Code-Zellen unten durch, um selbst einmal Objekterkennung auszuprobieren. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hboosJPmKK5i"
      },
      "outputs": [],
      "source": [
        "# benötige Bilbliotheken\n",
        "import torch\n",
        "from torchvision import models\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "# Funktion zur Vorverarbeitung der Bilder: Damit das Netz Bilder einlesen kann, müssen diese transformiert werden:\n",
        "#    Anpassung der Größe (256 x 256 Pixel)\n",
        "#    Rand wegschneiden (Bildgröße: 224×224 Pixel)\n",
        "#    Anpassung des Datentypes (Tensor)\n",
        "#    Normalisierung des Bildes, für jede der 3 Schichten (RGB)\n",
        "transform = transforms.Compose([            \n",
        "\t transforms.Resize(256),                    \n",
        "\t transforms.CenterCrop(224),                \n",
        "\t transforms.ToTensor(),                     \n",
        "\t transforms.Normalize(                      \n",
        "\t mean=[0.485, 0.456, 0.406],                \n",
        "\t std=[0.229, 0.224, 0.225]                  \n",
        "\t )])\n",
        "\n",
        "\n",
        "# Lade vortrainiertes Netz\n",
        "alexnet = models.alexnet(pretrained=True)\n",
        "\n",
        "#print(alexnet)\n",
        "\n",
        "# Setze das Modell in den Auswertungsmodus\n",
        "alexnet.eval();\n",
        "\n",
        "print(\"Es wurden erfolgreich alle Code-Bibliotheken und das vortrainierte Netz hochgeladen!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcny3wLGVLwS"
      },
      "outputs": [],
      "source": [
        "# Upload von lokalen Daten (von der eigenen Festplatte)\n",
        "from google.colab import files\n",
        "upload = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ery-GpRTQ1xg"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/msokur/girlsday2022\n",
        "img = Image.open(\"/content/girlsday2022/Bildklassifikation_girlsday_data/dog.jpg\")\n",
        "display(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RN6xiJfzWrk0"
      },
      "outputs": [],
      "source": [
        "# Vorverarbeitung des Bildes (Transformation und Hinzufügen einer weiteren Dimension)\n",
        "img_t = transform(img)\n",
        "img_in = torch.unsqueeze(img_t, 0)\n",
        "\n",
        "# Ausgabe der Bildgröße vorher und nachher\n",
        "print('Größe des Orginalbildes: ',img.size)\n",
        "print('Größe des transformierten Bildes: ', img_in.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bO-DypEnYo7O"
      },
      "outputs": [],
      "source": [
        "# Klassifizierung des Bildes durch das Netz\n",
        "out = alexnet(img_in)\n",
        "print('Größe des Netzoutputs: ',out.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "al48v47BZK_S"
      },
      "outputs": [],
      "source": [
        "# Auslesen der Klassen zur Übersetzung der Netzausgabe (Netz gibt nur eine 'Liste' an Zahlen zurück, jeder Eintrag in der Liste entspricht der Wahrscheinlichkeit dieser Klasse zuzugehören)\n",
        "with open('\"/content/girlsday2022/Bildklassifikation_girlsday_data/imagenet_classes.txt') as f:\n",
        "\t  labels = [line.strip() for line in f.readlines()]\n",
        "\n",
        "# finde Netzoutput mit höchstem Wert\n",
        "_, index = torch.max(out, 1)\n",
        "\n",
        "# berechen Wahrscheinlichkeit der gewählten Klasse\n",
        "percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
        "\n",
        "# gib Klasse und zugehörige Wahrscheinlichkeit aus\n",
        "print(labels[index[0]], percentage[index[0]].item())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpIqKXwJat0s"
      },
      "outputs": [],
      "source": [
        "# sortiere Netzoutput in absteigender Reihenfolge\n",
        "_, indices = torch.sort(out, descending=True)\n",
        "\n",
        "# gib die ersten 5 Klassen und deren Wahrscheinlichkeit an\n",
        "_, indices = torch.sort(out, descending=True)\n",
        "[(labels[idx], percentage[idx].item()) for idx in indices[0][:5]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ZikYunWbGqu"
      },
      "outputs": [],
      "source": [
        "# Ein neuer Versuch\n",
        "img = Image.open(\"/content/girlsday2022/Bildklassifikation_girlsday_data/strawberries.webp\")\n",
        "#img = Image.open(\"/content/girlsday2022/Bildklassifikation_girlsday_data/juri_green.jpg\")\n",
        "#img = Image.open(\"/content/girlsday2022/Bildklassifikation_girlsday_data/juri_snow.jpg\")\n",
        "#img = Image.open(\"/content/girlsday2022/Bildklassifikation_girlsday_data/kimba_snow.jpg\")\n",
        "#img = Image.open(\"/content/girlsday2022/Bildklassifikation_girlsday_data/kimba_green.jpg\")\n",
        "display(img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_CJFrBR-dhxc"
      },
      "outputs": [],
      "source": [
        "# Bildtransformation\n",
        "img_t = transform(img)\n",
        "img_in = torch.unsqueeze(img_t, 0)\n",
        "\n",
        "# Netzauswertung\n",
        "out = alexnet(img_in)\n",
        "\n",
        "# Ausgabe der 5 wahrscheinlichsten Klassen\n",
        "_, indices = torch.sort(out, descending=True)\n",
        "percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100\n",
        "[(labels[idx], percentage[idx].item()) for idx in indices[0][:5]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kw3rst8kbLwC"
      },
      "source": [
        "\n",
        "Jetzt habt ihr einmal ausprobiert, wie künstliche Neuronale Netze Objekte auf Bildern klassifizieren können! \n",
        "\n",
        "Wenn euch interessiert, wie genau diese Netze aussehen und trainiert werden, schaut doch mal in dieses Youtube-Video rein:\n",
        "\n",
        "https://www.youtube.com/watch?v=ya_6I9IVMzY"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Bildklassifikation_girlsday.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
